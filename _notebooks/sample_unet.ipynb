{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:20:15.622240Z",
     "start_time": "2018-12-08T18:20:14.420529Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import traceback\n",
    "import torchvision\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import pickle\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:20:15.680105Z",
     "start_time": "2018-12-08T18:20:15.624548Z"
    },
    "code_folding": [
     0,
     17,
     25,
     36,
     59,
     69,
     99,
     263
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    ''' conv -> BN -> relu -> conv -> BN -> relu'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mpconv(x)\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, out_ch//2, stride=2)\n",
    "        \n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, (diffX//2, diffX - diffX//2,\n",
    "                        diffY//2, diffY - diffY//2)\n",
    "                  )\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64,  128) #x2\n",
    "        self.down2 = down(128, 256) #x3\n",
    "        self.down3 = down(256, 512) #x4\n",
    "        self.down4 = down(512, 512) #x5\n",
    "        self.up1   = up(1024,256)\n",
    "        self.up2   = up(512,128)\n",
    "        self.up3   = up(256,64)\n",
    "        self.up4   = up(128,64)\n",
    "        self.outc  = outconv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5,x4) # (x5-512d + x4-512d  = 1024d--> 256d)\n",
    "        x = self.up2(x,x3)  # (x-256d + x3 - 256d = 512d --> 128d)\n",
    "        x = self.up3(x, x2) # (x-128d + x2 - 128d = 256d --> 64d)\n",
    "        x = self.up4(x,x1)  # (x-64d  + x1 - 64d  = 128d --> 64d)\n",
    "        x = self.outc(x)    # 64d --> n_classes_D\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class KaggleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ship_dir):\n",
    "        self.ship_dir = ship_dir\n",
    "        self.train_image_dir = os.path.join(self.ship_dir, 'train_v2')\n",
    "        self.test_image_dir = os.path.join(self.ship_dir, 'test_v2')\n",
    "        print(\"Starting preprocess\")\n",
    "        self.preprocess_pickle()\n",
    "        \n",
    "    def preprocess_pickle(self):\n",
    "        with open('all_batches_balancedTrain.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedTrain = pickle.load(f)\n",
    "        with open('all_batches_balancedValid.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedValid = pickle.load(f)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \n",
    "        def sample_ships(in_df, base_rep_val=1500):\n",
    "            if in_df['ships'].values[0]==0:\n",
    "                return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "            else:\n",
    "                return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "        masks = pd.read_csv(os.path.join(self.ship_dir, 'train_ship_segmentations_v2.csv'))\n",
    "        \n",
    "        masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "        unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "        print(\"Reach 1\")\n",
    "        unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "        unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "        # some files are too small/corrupt\n",
    "        print(\"Reach 1.2\")\n",
    "        unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                                       os.stat(os.path.join(self.train_image_dir, \n",
    "                                                                                            c_img_id)).st_size/1024)\n",
    "        print(\"Reach 2\")\n",
    "        unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "        masks.drop(['ships'], axis=1, inplace=True)\n",
    "        train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                         test_size = 0.3, \n",
    "                         stratify = unique_img_ids['ships'])\n",
    "        \n",
    "        \n",
    "        print(\"Reach 3\")\n",
    "        train_df = pd.merge(masks, train_ids)\n",
    "        valid_df = pd.merge(masks, valid_ids)\n",
    "        train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "\n",
    "        \n",
    "        print(\"Reach 4\")\n",
    "        balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "        print(\"Creating list\")\n",
    "        self.all_batches_balancedTrain = list(balanced_train_df.groupby('ImageId'))\n",
    "        self.all_batches_balancedValid = list(valid_df.groupby('ImageId'))\n",
    "        \n",
    "        with open('all_batches_balancedTrain.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedTrain, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open('all_batches_balancedValid.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedValid, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_batches_balancedTrain)\n",
    "    \n",
    "    def multi_rle_encode(self, img):\n",
    "        labels = label(img[:, :, 0])\n",
    "        return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "    # ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "    def rle_encode(self, img):\n",
    "        '''\n",
    "        img: numpy array, 1 - mask, 0 - background\n",
    "        Returns run length as string formated\n",
    "        '''\n",
    "        pixels = img.T.flatten()\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    def rle_decode(self, mask_rle, shape=(768, 768)):\n",
    "        '''\n",
    "        mask_rle: run-length as string formated (start length)\n",
    "        shape: (height,width) of array to return \n",
    "        Returns numpy array, 1 - mask, 0 - background\n",
    "        '''\n",
    "        s = mask_rle.split()\n",
    "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "        starts -= 1\n",
    "        ends = starts + lengths\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for lo, hi in zip(starts, ends):\n",
    "            img[lo:hi] = 1\n",
    "        return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "    def masks_as_image(self, in_mask_list):\n",
    "        # Take the individual ship masks and create a single mask array for all ships\n",
    "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "        #if isinstance(in_mask_list, list):\n",
    "        for mask in in_mask_list:\n",
    "            if isinstance(mask, str):\n",
    "                all_masks += self.rle_decode(mask)\n",
    "        return np.expand_dims(all_masks, -1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        factor = 5\n",
    "        rgb_path = os.path.join(self.train_image_dir, self.all_batches_balancedTrain[idx][0])\n",
    "        c_img = imread(rgb_path)\n",
    "        c_mask = self.masks_as_image( self.all_batches_balancedTrain[idx][1]['EncodedPixels'].values)\n",
    "        \n",
    "        c_img = np.stack(c_img, 0)/255.0\n",
    "        c_mask = np.stack(c_mask, 0)\n",
    "        \n",
    "#         c_img = resize(c_img, (c_img.shape[0] / 2, c_img.shape[1] / 2),\n",
    "#                        anti_aliasing=True)\n",
    "        \n",
    "#         c_mask = resize(c_mask, (c_mask.shape[0] / 2, c_mask.shape[1] / 2),\n",
    "#                        anti_aliasing=True)\n",
    "        \n",
    "        c_img = resize(c_img, (c_img.shape[0] // factor, c_img.shape[1] // factor),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_mask = resize(c_mask, (c_mask.shape[0] // factor, c_mask.shape[1] // factor),\n",
    "                       anti_aliasing=True)\n",
    "        c_img = c_img.transpose(-1, 0, 1)\n",
    "        c_mask = c_mask.transpose(-1, 0, 1)\n",
    "        \n",
    "        \n",
    "        return c_img.astype('f'), c_mask.astype('f')\n",
    "\n",
    "    def show(self, x, y):\n",
    "        f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "\n",
    "        axarr[0].imshow(x.transpose(-1, 1, 0))\n",
    "        axarr[1].imshow(y.transpose(-1, 1, 0)[:, :, 0])\n",
    "            \n",
    "def train(net, criterion, optimizer, epochs, trainLoader):\n",
    "    print ('Training has begun ...')\n",
    "    running_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            try:\n",
    "                print ('Epoch : {0} || BatchID : '.format(epoch,i)) \n",
    "                X,Y = data\n",
    "                print (X.size(), Y.size())\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                Y_   = net(X.cuda())\n",
    "                print (Y_.size())\n",
    "                loss = criterion(Y_, Y.cuda())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                print(\"Loss is {}\".format(running_loss))\n",
    "                if (1):    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss))\n",
    "                    running_loss = 0.0 \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                sys.exit(1)\n",
    "            \n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-08T18:20:14.423Z"
    },
    "code_folding": [
     15
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocess\n",
      "Training has begun ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/fastai/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.569840818177909e-05\n",
      "[1,     1] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.846106746001169e-05\n",
      "[1,     2] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.73114079493098e-05\n",
      "[1,     3] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.957056368468329e-05\n",
      "[1,     4] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.486938557121903e-05\n",
      "[1,     5] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.592514157295227e-05\n",
      "[1,     6] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.60720795369707e-05\n",
      "[1,     7] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.461632776539773e-05\n",
      "[1,     8] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.865598308853805e-05\n",
      "[1,     9] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.917428592918441e-05\n",
      "[1,    10] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.821229519322515e-05\n",
      "[1,    11] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.134131348924711e-05\n",
      "[1,    12] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.789049413986504e-05\n",
      "[1,    13] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.791662210365757e-05\n",
      "[1,    14] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.605078280903399e-05\n",
      "[1,    15] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.524045213358477e-05\n",
      "[1,    16] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.33735432731919e-05\n",
      "[1,    17] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.789956725900993e-05\n",
      "[1,    18] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.893548900028691e-05\n",
      "[1,    19] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.254603744717315e-05\n",
      "[1,    20] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.73849751567468e-05\n",
      "[1,    21] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.620721589773893e-05\n",
      "[1,    22] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.002720278454944e-05\n",
      "[1,    23] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.744265894871205e-05\n",
      "[1,    24] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.531111623393372e-05\n",
      "[1,    25] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.681806164328009e-05\n",
      "[1,    26] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.837469456717372e-05\n",
      "[1,    27] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.033499034354463e-05\n",
      "[1,    28] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.845622894819826e-05\n",
      "[1,    29] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.682217983528972e-05\n",
      "[1,    30] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.18431653897278e-05\n",
      "[1,    31] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.703653682256117e-05\n",
      "[1,    32] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.475037273252383e-05\n",
      "[1,    33] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.823046325938776e-05\n",
      "[1,    34] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.515035395044833e-05\n",
      "[1,    35] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.459524204023182e-05\n",
      "[1,    36] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.767791248625144e-05\n",
      "[1,    37] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.823797932360321e-05\n",
      "[1,    38] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.249961683759466e-05\n",
      "[1,    39] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.599667151225731e-05\n",
      "[1,    40] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.716211257502437e-05\n",
      "[1,    41] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.774856931064278e-05\n",
      "[1,    42] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.623888814123347e-05\n",
      "[1,    43] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.172259549610317e-05\n",
      "[1,    44] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.639494288014248e-05\n",
      "[1,    45] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.818666199455038e-05\n",
      "[1,    46] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.8014716564212e-05\n",
      "[1,    47] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.772638491587713e-05\n",
      "[1,    48] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.708812336204574e-05\n",
      "[1,    49] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.437314343405887e-05\n",
      "[1,    50] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.625450962223113e-05\n",
      "[1,    51] loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.720198482275009e-05\n",
      "[1,    52] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.85633092164062e-05\n",
      "[1,    53] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.921427459223196e-05\n",
      "[1,    54] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.644472498213872e-05\n",
      "[1,    55] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.94798179413192e-05\n",
      "[1,    56] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.726593321422115e-05\n",
      "[1,    57] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.739438296994194e-05\n",
      "[1,    58] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.550672307843342e-05\n",
      "[1,    59] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.64166543376632e-05\n",
      "[1,    60] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.448242831742391e-05\n",
      "[1,    61] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.530528819188476e-05\n",
      "[1,    62] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.50320905353874e-05\n",
      "[1,    63] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.665609155083075e-05\n",
      "[1,    64] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.569770968984812e-05\n",
      "[1,    65] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.860882760724053e-05\n",
      "[1,    66] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.642143464181572e-05\n",
      "[1,    67] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.562843529740348e-05\n",
      "[1,    68] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.926363468868658e-05\n",
      "[1,    69] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.636263035237789e-05\n",
      "[1,    70] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.627237937413156e-05\n",
      "[1,    71] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.590388122480363e-05\n",
      "[1,    72] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.934029417810962e-05\n",
      "[1,    73] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.616186485392973e-05\n",
      "[1,    74] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.839507452445105e-05\n",
      "[1,    75] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.554603507742286e-05\n",
      "[1,    76] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.827376975910738e-05\n",
      "[1,    77] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.682234718231484e-05\n",
      "[1,    78] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.405513315461576e-05\n",
      "[1,    79] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.937710324767977e-05\n",
      "[1,    80] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.643181743333116e-05\n",
      "[1,    81] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.795801502652466e-05\n",
      "[1,    82] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.531807932537049e-05\n",
      "[1,    83] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.835170981707051e-05\n",
      "[1,    84] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.701422146055847e-05\n",
      "[1,    85] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.825435022823513e-05\n",
      "[1,    86] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.429262768710032e-05\n",
      "[1,    87] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.166383486241102e-05\n",
      "[1,    88] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.711958460276946e-05\n",
      "[1,    89] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.53717395127751e-05\n",
      "[1,    90] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.577491487609223e-05\n",
      "[1,    91] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.761086453683674e-05\n",
      "[1,    92] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.673379150219262e-05\n",
      "[1,    93] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.677120447624475e-05\n",
      "[1,    94] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.735740655334666e-05\n",
      "[1,    95] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.794446719344705e-05\n",
      "[1,    96] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.611950422869995e-05\n",
      "[1,    97] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.56280351197347e-05\n",
      "[1,    98] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.776194979669526e-05\n",
      "[1,    99] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.733070378890261e-05\n",
      "[1,   100] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.824472413631156e-05\n",
      "[1,   101] loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.751909288344905e-05\n",
      "[1,   102] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.367628131760284e-05\n",
      "[1,   103] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.700241985730827e-05\n",
      "[1,   104] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.637112867087126e-05\n",
      "[1,   105] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.888479740358889e-05\n",
      "[1,   106] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.086044545052573e-05\n",
      "[1,   107] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.725379691692069e-05\n",
      "[1,   108] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.981310045579448e-05\n",
      "[1,   109] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.724527677055448e-05\n",
      "[1,   110] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.065340807661414e-05\n",
      "[1,   111] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.598642696393654e-05\n",
      "[1,   112] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.150065696099773e-05\n",
      "[1,   113] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.258061279775575e-05\n",
      "[1,   114] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.642310083610937e-05\n",
      "[1,   115] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.596308569191024e-05\n",
      "[1,   116] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.399237802019343e-05\n",
      "[1,   117] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.003240509424359e-05\n",
      "[1,   118] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.970421575009823e-05\n",
      "[1,   119] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.603446283610538e-05\n",
      "[1,   120] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.815614662831649e-05\n",
      "[1,   121] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.885749801062047e-05\n",
      "[1,   122] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.793152326485142e-05\n",
      "[1,   123] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.711842772550881e-05\n",
      "[1,   124] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.611409819219261e-05\n",
      "[1,   125] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.755281694699079e-05\n",
      "[1,   126] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.489095878554508e-05\n",
      "[1,   127] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.753303361823782e-05\n",
      "[1,   128] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.752780948067084e-05\n",
      "[1,   129] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.896975876064971e-05\n",
      "[1,   130] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.720876601524651e-05\n",
      "[1,   131] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.414144783979282e-05\n",
      "[1,   132] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.468260446330532e-05\n",
      "[1,   133] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.615183858433738e-05\n",
      "[1,   134] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.721386646153405e-05\n",
      "[1,   135] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.564273983007297e-05\n",
      "[1,   136] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.002002869034186e-05\n",
      "[1,   137] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.555609045084566e-05\n",
      "[1,   138] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.408521534875035e-05\n",
      "[1,   139] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.658890535822138e-05\n",
      "[1,   140] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.29032578621991e-05\n",
      "[1,   141] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.93587532825768e-05\n",
      "[1,   142] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.739022112218663e-05\n",
      "[1,   143] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.560661470051855e-05\n",
      "[1,   144] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.762508175801486e-05\n",
      "[1,   145] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.488264964194968e-05\n",
      "[1,   146] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.674010703340173e-05\n",
      "[1,   147] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.532545714639127e-05\n",
      "[1,   148] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.664661825401708e-05\n",
      "[1,   149] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.608554005855694e-05\n",
      "[1,   150] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.622118573635817e-05\n",
      "[1,   151] loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.009323937585577e-05\n",
      "[1,   152] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.765371992718428e-05\n",
      "[1,   153] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.837373414076865e-05\n",
      "[1,   154] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.448058750014752e-05\n",
      "[1,   155] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.93573708506301e-05\n",
      "[1,   156] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.78066532802768e-05\n",
      "[1,   157] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.920110510895029e-05\n",
      "[1,   158] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.53568674554117e-05\n",
      "[1,   159] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.66794037190266e-05\n",
      "[1,   160] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.511780131608248e-05\n",
      "[1,   161] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.643442950211465e-05\n",
      "[1,   162] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.731257210252807e-05\n",
      "[1,   163] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.573595939902589e-05\n",
      "[1,   164] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.601702964166179e-05\n",
      "[1,   165] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.824919885024428e-05\n",
      "[1,   166] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.609168096678331e-05\n",
      "[1,   167] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.596377690788358e-05\n",
      "[1,   168] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.622225530212745e-05\n",
      "[1,   169] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.760358857922256e-05\n",
      "[1,   170] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.814401033101603e-05\n",
      "[1,   171] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.624316640431061e-05\n",
      "[1,   172] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.479314081138e-05\n",
      "[1,   173] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.738966087345034e-05\n",
      "[1,   174] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.741878653177992e-05\n",
      "[1,   175] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.68488462199457e-05\n",
      "[1,   176] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.79961483203806e-05\n",
      "[1,   177] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.76138695073314e-05\n",
      "[1,   178] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.782798638800159e-05\n",
      "[1,   179] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.811257091816515e-05\n",
      "[1,   180] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.499588537029922e-05\n",
      "[1,   181] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.957557681947947e-05\n",
      "[1,   182] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.697666296735406e-05\n",
      "[1,   183] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.883313082857057e-05\n",
      "[1,   184] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.707795884925872e-05\n",
      "[1,   185] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.620505493832752e-05\n",
      "[1,   186] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.96168897068128e-05\n",
      "[1,   187] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.706107862759382e-05\n",
      "[1,   188] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.760603330098093e-05\n",
      "[1,   189] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.723921589786187e-05\n",
      "[1,   190] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.65466975281015e-05\n",
      "[1,   191] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.360432209679857e-05\n",
      "[1,   192] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.803511834936216e-05\n",
      "[1,   193] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.618995732627809e-05\n",
      "[1,   194] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.387156801996753e-05\n",
      "[1,   195] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.778160215821117e-05\n",
      "[1,   196] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.736048428341746e-05\n",
      "[1,   197] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.698353874729946e-05\n",
      "[1,   198] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.463147630915046e-05\n",
      "[1,   199] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.454720616806298e-05\n",
      "[1,   200] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.817211735527962e-05\n",
      "[1,   201] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.625889702467248e-05\n",
      "[1,   202] loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.899132469901815e-05\n",
      "[1,   203] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.81523558543995e-05\n",
      "[1,   204] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.607301813550293e-05\n",
      "[1,   205] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 8.413241448579356e-05\n",
      "[1,   206] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.818326412234455e-05\n",
      "[1,   207] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.517730409745127e-05\n",
      "[1,   208] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.684649608563632e-05\n",
      "[1,   209] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.633547647856176e-05\n",
      "[1,   210] loss: 0.000\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n",
      "torch.Size([4, 1, 153, 153])\n",
      "Loss is 7.524114334955812e-05\n",
      "[1,   211] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    net       = UNet(3, 1).cuda()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = dice_coeff\n",
    "    \n",
    "    ship_dir = '/media/shivam/DATA/airbus-tracking/'\n",
    "    trainDataset = KaggleDataset(ship_dir)\n",
    "    \n",
    "    trainDataLoader   = torch.utils.data.DataLoader(\n",
    "            trainDataset\n",
    "            , batch_size=4,shuffle=True\n",
    "            , num_workers=1, pin_memory=True)\n",
    "    \n",
    "    train(net, criterion, optimizer, 2, trainDataLoader)\n",
    "    \n",
    "    \n",
    "    verbose = 0\n",
    "    if verbose:\n",
    "        y = net(torch.Tensor(np.random.random((1,3,256,256))))\n",
    "        print (y.size())\n",
    "        \n",
    "        print (net)\n",
    "        \n",
    "        for param in net.parameters():\n",
    "            print (param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-08T18:20:14.426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del net\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T16:06:56.841890Z",
     "start_time": "2018-12-08T16:06:56.823606Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-08T18:20:14.430Z"
    },
    "code_folding": [
     10,
     16,
     66,
     71,
     82
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class KaggleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ship_dir):\n",
    "        self.ship_dir = ship_dir\n",
    "        self.train_image_dir = os.path.join(self.ship_dir, 'train_v2')\n",
    "        self.test_image_dir = os.path.join(self.ship_dir, 'test_v2')\n",
    "        print(\"Starting preprocess\")\n",
    "        self.preprocess_pickle()\n",
    "        \n",
    "    def preprocess_pickle(self):\n",
    "        with open('all_batches_balancedTrain.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedTrain = pickle.load(f)\n",
    "        with open('all_batches_balancedValid.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedValid = pickle.load(f)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \n",
    "        def sample_ships(in_df, base_rep_val=1500):\n",
    "            if in_df['ships'].values[0]==0:\n",
    "                return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "            else:\n",
    "                return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "        masks = pd.read_csv(os.path.join(self.ship_dir, 'train_ship_segmentations_v2.csv'))\n",
    "        \n",
    "        masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "        unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "        print(\"Reach 1\")\n",
    "        unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "        unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "        # some files are too small/corrupt\n",
    "        print(\"Reach 1.2\")\n",
    "        unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                                       os.stat(os.path.join(self.train_image_dir, \n",
    "                                                                                            c_img_id)).st_size/1024)\n",
    "        print(\"Reach 2\")\n",
    "        unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "        masks.drop(['ships'], axis=1, inplace=True)\n",
    "        train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                         test_size = 0.3, \n",
    "                         stratify = unique_img_ids['ships'])\n",
    "        \n",
    "        \n",
    "        print(\"Reach 3\")\n",
    "        train_df = pd.merge(masks, train_ids)\n",
    "        valid_df = pd.merge(masks, valid_ids)\n",
    "        train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "\n",
    "        \n",
    "        print(\"Reach 4\")\n",
    "        balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "        print(\"Creating list\")\n",
    "        self.all_batches_balancedTrain = list(balanced_train_df.groupby('ImageId'))\n",
    "        self.all_batches_balancedValid = list(valid_df.groupby('ImageId'))\n",
    "        \n",
    "        with open('all_batches_balancedTrain.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedTrain, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open('all_batches_balancedValid.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedValid, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_batches_balancedTrain)\n",
    "    \n",
    "    def multi_rle_encode(self, img):\n",
    "        labels = label(img[:, :, 0])\n",
    "        return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "    # ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "    def rle_encode(self, img):\n",
    "        '''\n",
    "        img: numpy array, 1 - mask, 0 - background\n",
    "        Returns run length as string formated\n",
    "        '''\n",
    "        pixels = img.T.flatten()\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    def rle_decode(self, mask_rle, shape=(768, 768)):\n",
    "        '''\n",
    "        mask_rle: run-length as string formated (start length)\n",
    "        shape: (height,width) of array to return \n",
    "        Returns numpy array, 1 - mask, 0 - background\n",
    "        '''\n",
    "        s = mask_rle.split()\n",
    "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "        starts -= 1\n",
    "        ends = starts + lengths\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for lo, hi in zip(starts, ends):\n",
    "            img[lo:hi] = 1\n",
    "        return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "    def masks_as_image(self, in_mask_list):\n",
    "        # Take the individual ship masks and create a single mask array for all ships\n",
    "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "        #if isinstance(in_mask_list, list):\n",
    "        for mask in in_mask_list:\n",
    "            if isinstance(mask, str):\n",
    "                all_masks += self.rle_decode(mask)\n",
    "        return np.expand_dims(all_masks, -1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path = os.path.join(self.train_image_dir, self.all_batches_balancedTrain[idx][0])\n",
    "        c_img = imread(rgb_path)\n",
    "        c_mask = self.masks_as_image( self.all_batches_balancedTrain[idx][1]['EncodedPixels'].values)\n",
    "        \n",
    "        c_img = np.stack(c_img, 0)/255.0\n",
    "        c_mask = np.stack(c_mask, 0)\n",
    "        \n",
    "        c_img = resize(c_img, (c_img.shape[0] / 2, c_img.shape[1] / 2),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_mask = resize(c_mask, (c_mask.shape[0] / 2, c_mask.shape[1] / 2),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_img = c_img.transpose(-1, 0, 1)\n",
    "        c_mask = c_mask.transpose(-1, 0, 1)\n",
    "        \n",
    "        \n",
    "        return c_img, c_mask\n",
    "\n",
    "    def show(self, x, y):\n",
    "        f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "\n",
    "        axarr[0].imshow(x.transpose(-1, 1, 0))\n",
    "        axarr[1].imshow(y.transpose(-1, 1, 0)[:, :, 0])\n",
    "            \n",
    "\n",
    "if(10):\n",
    "    ship_dir = '/media/shivam/DATA/airbus-tracking/'\n",
    "    trainDataset = KaggleDataset(ship_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-08T18:20:14.432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # x, y = trainDataset[1]\n",
    "\n",
    "# # yp = np.ones_like(y)\n",
    "# y = torch.from_numpy(np.random.random((4, 1, 153, 153)))\n",
    "# yp = torch.from_numpy(np.random.random((4, 1, 153, 153)))\n",
    "\n",
    "# print(dice_coeff(y, yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-08T18:20:14.434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a,b = trainDataset[199]\n",
    "# dataLoader = torch.utils.data.DataLoader(trainDataset\n",
    "#             , batch_size=4,\n",
    "#             shuffle=True, num_workers=1, pin_memory=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
