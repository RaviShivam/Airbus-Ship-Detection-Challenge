{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:08.119976Z",
     "start_time": "2018-12-08T17:08:07.514071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:08.360895Z",
     "start_time": "2018-12-08T17:08:08.121427Z"
    },
    "code_folding": [
     0,
     17,
     25,
     36,
     59,
     69,
     114
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    ''' conv -> BN -> relu -> conv -> BN -> relu'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mpconv(x)\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, out_ch//2, stride=2)\n",
    "        \n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, (diffX//2, diffX - diffX//2,\n",
    "                        diffY//2, diffY - diffY//2)\n",
    "                  )\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64,  128) #x2\n",
    "        self.down2 = down(128, 256) #x3\n",
    "        self.down3 = down(256, 512) #x4\n",
    "        self.down4 = down(512, 512) #x5\n",
    "        self.up1   = up(1024,256)\n",
    "        self.up2   = up(512,128)\n",
    "        self.up3   = up(256,64)\n",
    "        self.up4   = up(128,64)\n",
    "        self.outc  = outconv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5,x4) # (x5-512d + x4-512d  = 1024d--> 256d)\n",
    "        x = self.up2(x,x3)  # (x-256d + x3 - 256d = 512d --> 128d)\n",
    "        x = self.up3(x, x2) # (x-128d + x2 - 128d = 256d --> 64d)\n",
    "        x = self.up4(x,x1)  # (x-64d  + x1 - 64d  = 128d --> 64d)\n",
    "        x = self.outc(x)    # 64d --> n_classes_D\n",
    "        \n",
    "        return x\n",
    "\n",
    "class KaggleDataset(Dataset):\n",
    "    def __init__(self, datatype):\n",
    "        self.datatype = datatype\n",
    "    \n",
    "    def size(self):\n",
    "        return (1,1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 3\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = np.random.random((3,256,256)).astype('f')\n",
    "        Y = np.random.random((2,256,256)).astype('f')\n",
    "        return X, Y\n",
    "    \n",
    "\n",
    "def train(net, criterion, optimizer, epochs, trainLoader):\n",
    "    print ('Training has begun ...')\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            try:\n",
    "                print ('Epoch : {0} || BatchID : '.format(epoch,i)) \n",
    "                X,Y = data\n",
    "                print (X.size(), Y.size())\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                Y_   = net(X.cuda())\n",
    "                print (Y_.size())\n",
    "                loss = criterion(Y_, Y.cuda())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0 \n",
    "            except Exception:\n",
    "                sys.exit(1)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:25.158255Z",
     "start_time": "2018-12-08T17:08:16.953342Z"
    },
    "code_folding": [
     15
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has begun ...\n",
      "Epoch : 0 || BatchID : \n",
      "torch.Size([3, 3, 256, 256]) torch.Size([3, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strider/anaconda3/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strider/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([3, 1, 256, 256])) that is different to the input size (torch.Size([3, 2, 256, 256])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strider/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    net       = UNet(3, 2).cuda()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    trainDataset      = KaggleDataset('train')\n",
    "    trainDataLoader   = torch.utils.data.DataLoader(\n",
    "            trainDataset\n",
    "            , batch_size=4,shuffle=True\n",
    "            , num_workers=1, pin_memory=True)\n",
    "    \n",
    "    train(net, criterion, optimizer, 2, trainDataLoader)\n",
    "    \n",
    "    \n",
    "    verbose = 0\n",
    "    if verbose:\n",
    "        y = net(torch.Tensor(np.random.random((1,3,256,256))))\n",
    "        print (y.size())\n",
    "        \n",
    "        print (net)\n",
    "        \n",
    "        for param in net.parameters():\n",
    "            print (param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:08.680983Z",
     "start_time": "2018-12-08T16:08:07.499Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del net\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T16:06:56.841890Z",
     "start_time": "2018-12-08T16:06:56.823606Z"
    },
    "collapsed": false
   },
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:08.681203Z",
     "start_time": "2018-12-08T16:08:07.501Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class KaggleDataset(Dataset):\n",
    "#     def __init__(self, datatype):\n",
    "#         self.datatype = datatype\n",
    "    \n",
    "#     def size(self):\n",
    "#         return (1,1)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return 3\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         X = np.random.random((3,256,256)).astype('f')\n",
    "#         Y = np.random.random((1,256,256)).astype('f')\n",
    "#         print (type(X))\n",
    "#         return X, Y\n",
    "\n",
    "# trainDataset = KaggleDataset('train')\n",
    "# a,b = trainDataset[1]\n",
    "# print (a.shape, b.shape)\n",
    "# dataLoader = torch.utils.data.DataLoader(trainDataset\n",
    "#             , batch_size=4,\n",
    "#             shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T17:08:08.681385Z",
     "start_time": "2018-12-08T16:08:07.501Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (len(trainDataset))\n",
    "\n",
    "# for i, data in enumerate(dataLoader):\n",
    "#     print (i)\n",
    "#     X,Y = data\n",
    "#     print (type(X), X.size())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
