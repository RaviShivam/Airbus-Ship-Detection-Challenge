{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:14.339414Z",
     "start_time": "2018-12-08T18:19:13.116145Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import traceback\n",
    "import torchvision\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import pickle\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:14.398354Z",
     "start_time": "2018-12-08T18:19:14.341817Z"
    },
    "code_folding": [
     0,
     17,
     25,
     36,
     59,
     69,
     99,
     263
    ]
   },
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    ''' conv -> BN -> relu -> conv -> BN -> relu'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mpconv(x)\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, out_ch//2, stride=2)\n",
    "        \n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, (diffX//2, diffX - diffX//2,\n",
    "                        diffY//2, diffY - diffY//2)\n",
    "                  )\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64,  128) #x2\n",
    "        self.down2 = down(128, 256) #x3\n",
    "        self.down3 = down(256, 512) #x4\n",
    "        self.down4 = down(512, 512) #x5\n",
    "        self.up1   = up(1024,256)\n",
    "        self.up2   = up(512,128)\n",
    "        self.up3   = up(256,64)\n",
    "        self.up4   = up(128,64)\n",
    "        self.outc  = outconv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5,x4) # (x5-512d + x4-512d  = 1024d--> 256d)\n",
    "        x = self.up2(x,x3)  # (x-256d + x3 - 256d = 512d --> 128d)\n",
    "        x = self.up3(x, x2) # (x-128d + x2 - 128d = 256d --> 64d)\n",
    "        x = self.up4(x,x1)  # (x-64d  + x1 - 64d  = 128d --> 64d)\n",
    "        x = self.outc(x)    # 64d --> n_classes_D\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class KaggleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ship_dir):\n",
    "        self.ship_dir = ship_dir\n",
    "        self.train_image_dir = os.path.join(self.ship_dir, 'train_v2')\n",
    "        self.test_image_dir = os.path.join(self.ship_dir, 'test_v2')\n",
    "        print(\"Starting preprocess\")\n",
    "        self.preprocess_pickle()\n",
    "        \n",
    "    def preprocess_pickle(self):\n",
    "        with open('all_batches_balancedTrain.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedTrain = pickle.load(f)\n",
    "        with open('all_batches_balancedValid.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedValid = pickle.load(f)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \n",
    "        def sample_ships(in_df, base_rep_val=1500):\n",
    "            if in_df['ships'].values[0]==0:\n",
    "                return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "            else:\n",
    "                return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "        masks = pd.read_csv(os.path.join(self.ship_dir, 'train_ship_segmentations_v2.csv'))\n",
    "        \n",
    "        masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "        unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "        print(\"Reach 1\")\n",
    "        unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "        unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "        # some files are too small/corrupt\n",
    "        print(\"Reach 1.2\")\n",
    "        unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                                       os.stat(os.path.join(self.train_image_dir, \n",
    "                                                                                            c_img_id)).st_size/1024)\n",
    "        print(\"Reach 2\")\n",
    "        unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "        masks.drop(['ships'], axis=1, inplace=True)\n",
    "        train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                         test_size = 0.3, \n",
    "                         stratify = unique_img_ids['ships'])\n",
    "        \n",
    "        \n",
    "        print(\"Reach 3\")\n",
    "        train_df = pd.merge(masks, train_ids)\n",
    "        valid_df = pd.merge(masks, valid_ids)\n",
    "        train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "\n",
    "        \n",
    "        print(\"Reach 4\")\n",
    "        balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "        print(\"Creating list\")\n",
    "        self.all_batches_balancedTrain = list(balanced_train_df.groupby('ImageId'))\n",
    "        self.all_batches_balancedValid = list(valid_df.groupby('ImageId'))\n",
    "        \n",
    "        with open('all_batches_balancedTrain.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedTrain, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open('all_batches_balancedValid.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedValid, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_batches_balancedTrain)\n",
    "    \n",
    "    def multi_rle_encode(self, img):\n",
    "        labels = label(img[:, :, 0])\n",
    "        return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "    # ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "    def rle_encode(self, img):\n",
    "        '''\n",
    "        img: numpy array, 1 - mask, 0 - background\n",
    "        Returns run length as string formated\n",
    "        '''\n",
    "        pixels = img.T.flatten()\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    def rle_decode(self, mask_rle, shape=(768, 768)):\n",
    "        '''\n",
    "        mask_rle: run-length as string formated (start length)\n",
    "        shape: (height,width) of array to return \n",
    "        Returns numpy array, 1 - mask, 0 - background\n",
    "        '''\n",
    "        s = mask_rle.split()\n",
    "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "        starts -= 1\n",
    "        ends = starts + lengths\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for lo, hi in zip(starts, ends):\n",
    "            img[lo:hi] = 1\n",
    "        return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "    def masks_as_image(self, in_mask_list):\n",
    "        # Take the individual ship masks and create a single mask array for all ships\n",
    "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "        #if isinstance(in_mask_list, list):\n",
    "        for mask in in_mask_list:\n",
    "            if isinstance(mask, str):\n",
    "                all_masks += self.rle_decode(mask)\n",
    "        return np.expand_dims(all_masks, -1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        factor = 5\n",
    "        rgb_path = os.path.join(self.train_image_dir, self.all_batches_balancedTrain[idx][0])\n",
    "        c_img = imread(rgb_path)\n",
    "        c_mask = self.masks_as_image( self.all_batches_balancedTrain[idx][1]['EncodedPixels'].values)\n",
    "        \n",
    "        c_img = np.stack(c_img, 0)/255.0\n",
    "        c_mask = np.stack(c_mask, 0)\n",
    "        \n",
    "#         c_img = resize(c_img, (c_img.shape[0] / 2, c_img.shape[1] / 2),\n",
    "#                        anti_aliasing=True)\n",
    "        \n",
    "#         c_mask = resize(c_mask, (c_mask.shape[0] / 2, c_mask.shape[1] / 2),\n",
    "#                        anti_aliasing=True)\n",
    "        \n",
    "        c_img = resize(c_img, (c_img.shape[0] // factor, c_img.shape[1] // factor),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_mask = resize(c_mask, (c_mask.shape[0] // factor, c_mask.shape[1] // factor),\n",
    "                       anti_aliasing=True)\n",
    "        c_img = c_img.transpose(-1, 0, 1)\n",
    "        c_mask = c_mask.transpose(-1, 0, 1)\n",
    "        \n",
    "        \n",
    "        return c_img.astype('f'), c_mask.astype('f')\n",
    "\n",
    "    def show(self, x, y):\n",
    "        f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "\n",
    "        axarr[0].imshow(x.transpose(-1, 1, 0))\n",
    "        axarr[1].imshow(y.transpose(-1, 1, 0)[:, :, 0])\n",
    "            \n",
    "def train(net, criterion, optimizer, epochs, trainLoader):\n",
    "    print ('Training has begun ...')\n",
    "    running_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            try:\n",
    "                print ('Epoch : {0} || BatchID : '.format(epoch,i)) \n",
    "                X,Y = data\n",
    "                print (X.size(), Y.size())\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                Y_   = net(X.cuda())\n",
    "                print (Y_.size())\n",
    "                loss = criterion(Y_, Y.cuda())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                print(\"Loss is {}\".format(running_loss))\n",
    "                if (1):    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss))\n",
    "                    running_loss = 0.0 \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                sys.exit(1)\n",
    "            \n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:45.097092Z",
     "start_time": "2018-12-08T18:19:14.401687Z"
    },
    "code_folding": [
     15
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocess\n",
      "Training has begun ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/fastai/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 || BatchID : \n",
      "torch.Size([4, 3, 153, 153]) torch.Size([4, 1, 153, 153])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 153, 153])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-8f8209213988>\", line 255, in train\n",
      "    print(\"Loss is {}\".format(running_lossing))\n",
      "NameError: name 'running_lossing' is not defined\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    net       = UNet(3, 1).cuda()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = dice_coeff\n",
    "    \n",
    "    ship_dir = '/media/shivam/DATA/airbus-tracking/'\n",
    "    trainDataset = KaggleDataset(ship_dir)\n",
    "    \n",
    "    trainDataLoader   = torch.utils.data.DataLoader(\n",
    "            trainDataset\n",
    "            , batch_size=4,shuffle=True\n",
    "            , num_workers=1, pin_memory=True)\n",
    "    \n",
    "    train(net, criterion, optimizer, 2, trainDataLoader)\n",
    "    \n",
    "    \n",
    "    verbose = 0\n",
    "    if verbose:\n",
    "        y = net(torch.Tensor(np.random.random((1,3,256,256))))\n",
    "        print (y.size())\n",
    "        \n",
    "        print (net)\n",
    "        \n",
    "        for param in net.parameters():\n",
    "            print (param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:45.101998Z",
     "start_time": "2018-12-08T18:19:13.121Z"
    }
   },
   "outputs": [],
   "source": [
    "# del net\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T16:06:56.841890Z",
     "start_time": "2018-12-08T16:06:56.823606Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:45.103889Z",
     "start_time": "2018-12-08T18:19:13.124Z"
    },
    "code_folding": [
     10,
     16,
     66,
     71,
     82
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class KaggleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ship_dir):\n",
    "        self.ship_dir = ship_dir\n",
    "        self.train_image_dir = os.path.join(self.ship_dir, 'train_v2')\n",
    "        self.test_image_dir = os.path.join(self.ship_dir, 'test_v2')\n",
    "        print(\"Starting preprocess\")\n",
    "        self.preprocess_pickle()\n",
    "        \n",
    "    def preprocess_pickle(self):\n",
    "        with open('all_batches_balancedTrain.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedTrain = pickle.load(f)\n",
    "        with open('all_batches_balancedValid.pickle', 'rb') as f:\n",
    "            self.all_batches_balancedValid = pickle.load(f)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \n",
    "        def sample_ships(in_df, base_rep_val=1500):\n",
    "            if in_df['ships'].values[0]==0:\n",
    "                return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "            else:\n",
    "                return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "        masks = pd.read_csv(os.path.join(self.ship_dir, 'train_ship_segmentations_v2.csv'))\n",
    "        \n",
    "        masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "        unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "        print(\"Reach 1\")\n",
    "        unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "        unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "        # some files are too small/corrupt\n",
    "        print(\"Reach 1.2\")\n",
    "        unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                                       os.stat(os.path.join(self.train_image_dir, \n",
    "                                                                                            c_img_id)).st_size/1024)\n",
    "        print(\"Reach 2\")\n",
    "        unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "        masks.drop(['ships'], axis=1, inplace=True)\n",
    "        train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                         test_size = 0.3, \n",
    "                         stratify = unique_img_ids['ships'])\n",
    "        \n",
    "        \n",
    "        print(\"Reach 3\")\n",
    "        train_df = pd.merge(masks, train_ids)\n",
    "        valid_df = pd.merge(masks, valid_ids)\n",
    "        train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "\n",
    "        \n",
    "        print(\"Reach 4\")\n",
    "        balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "        print(\"Creating list\")\n",
    "        self.all_batches_balancedTrain = list(balanced_train_df.groupby('ImageId'))\n",
    "        self.all_batches_balancedValid = list(valid_df.groupby('ImageId'))\n",
    "        \n",
    "        with open('all_batches_balancedTrain.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedTrain, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open('all_batches_balancedValid.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.all_batches_balancedValid, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_batches_balancedTrain)\n",
    "    \n",
    "    def multi_rle_encode(self, img):\n",
    "        labels = label(img[:, :, 0])\n",
    "        return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "    # ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "    def rle_encode(self, img):\n",
    "        '''\n",
    "        img: numpy array, 1 - mask, 0 - background\n",
    "        Returns run length as string formated\n",
    "        '''\n",
    "        pixels = img.T.flatten()\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "\n",
    "    def rle_decode(self, mask_rle, shape=(768, 768)):\n",
    "        '''\n",
    "        mask_rle: run-length as string formated (start length)\n",
    "        shape: (height,width) of array to return \n",
    "        Returns numpy array, 1 - mask, 0 - background\n",
    "        '''\n",
    "        s = mask_rle.split()\n",
    "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "        starts -= 1\n",
    "        ends = starts + lengths\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for lo, hi in zip(starts, ends):\n",
    "            img[lo:hi] = 1\n",
    "        return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "    def masks_as_image(self, in_mask_list):\n",
    "        # Take the individual ship masks and create a single mask array for all ships\n",
    "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "        #if isinstance(in_mask_list, list):\n",
    "        for mask in in_mask_list:\n",
    "            if isinstance(mask, str):\n",
    "                all_masks += self.rle_decode(mask)\n",
    "        return np.expand_dims(all_masks, -1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path = os.path.join(self.train_image_dir, self.all_batches_balancedTrain[idx][0])\n",
    "        c_img = imread(rgb_path)\n",
    "        c_mask = self.masks_as_image( self.all_batches_balancedTrain[idx][1]['EncodedPixels'].values)\n",
    "        \n",
    "        c_img = np.stack(c_img, 0)/255.0\n",
    "        c_mask = np.stack(c_mask, 0)\n",
    "        \n",
    "        c_img = resize(c_img, (c_img.shape[0] / 2, c_img.shape[1] / 2),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_mask = resize(c_mask, (c_mask.shape[0] / 2, c_mask.shape[1] / 2),\n",
    "                       anti_aliasing=True)\n",
    "        \n",
    "        c_img = c_img.transpose(-1, 0, 1)\n",
    "        c_mask = c_mask.transpose(-1, 0, 1)\n",
    "        \n",
    "        \n",
    "        return c_img, c_mask\n",
    "\n",
    "    def show(self, x, y):\n",
    "        f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "\n",
    "        axarr[0].imshow(x.transpose(-1, 1, 0))\n",
    "        axarr[1].imshow(y.transpose(-1, 1, 0)[:, :, 0])\n",
    "            \n",
    "\n",
    "if(10):\n",
    "    ship_dir = '/media/shivam/DATA/airbus-tracking/'\n",
    "    trainDataset = KaggleDataset(ship_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:45.106074Z",
     "start_time": "2018-12-08T18:19:13.126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # x, y = trainDataset[1]\n",
    "\n",
    "# # yp = np.ones_like(y)\n",
    "# y = torch.from_numpy(np.random.random((4, 1, 153, 153)))\n",
    "# yp = torch.from_numpy(np.random.random((4, 1, 153, 153)))\n",
    "\n",
    "# print(dice_coeff(y, yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T18:19:45.108672Z",
     "start_time": "2018-12-08T18:19:13.127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a,b = trainDataset[199]\n",
    "# dataLoader = torch.utils.data.DataLoader(trainDataset\n",
    "#             , batch_size=4,\n",
    "#             shuffle=True, num_workers=1, pin_memory=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
